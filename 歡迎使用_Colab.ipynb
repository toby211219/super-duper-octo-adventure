{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***1***"
      ],
      "metadata": {
        "id": "vk25gUI6OLq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install necessary libraries\n",
        "# This line installs the Google Generative AI Python client library.\n",
        "# Skip this step if you have already installed it.\n",
        "!pip install google-generativeai -q\n",
        "\n",
        "# Import necessary libraries\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# 2. Load the API key\n",
        "# Securely load your Google AI Studio API key from Colab Secrets Manager.\n",
        "# Make sure to add your key to the Secrets Manager and name it 'GOOGLE_API_KEY'.\n",
        "api_key = None\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    if api_key is None:\n",
        "        print(\"API key not found in Colab Secrets Manager. Please add it as 'GOOGLE_API_KEY'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the API key: {e}\")\n",
        "\n",
        "if not api_key:\n",
        "    print(\"Failed to load API key. Please check Secrets Manager settings.\")\n",
        "else:\n",
        "    print(\"API key loaded successfully.\")\n",
        "    # 3. Initialize the Generative AI model\n",
        "    # Initialize the Google Generative AI model using the loaded key.\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        # Choose a model that supports the generate_content method, e.g., 'gemini-pro' or 'gemini-1.5-flash'\n",
        "        # You can use genai.list_models() to see available models\n",
        "        model_name = 'gemini-1.5-flash' # Or 'gemini-pro' or another suitable model\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        print(f\"Google Generative AI model '{model_name}' initialized.\")\n",
        "\n",
        "        # --- Add code for user input prompt ---\n",
        "        prompt_text = input(\"Please enter your question: \")\n",
        "        # --- End of code for user input prompt ---\n",
        "\n",
        "        # 4. Send the prompt and capture the response\n",
        "        print(f\"\\nPrompt text created: {prompt_text}\")\n",
        "\n",
        "        print(\"Sending prompt to the model...\")\n",
        "        response = model.generate_content(prompt_text)\n",
        "        print(\"Prompt sent, response received.\")\n",
        "\n",
        "        # 5. Process and display the response\n",
        "        # Get the model's generated response and display it.\n",
        "        try:\n",
        "            response_text = response.text\n",
        "            print(\"\\n--- AI Model Response ---\")\n",
        "            print(response_text)\n",
        "            print(\"-------------------------\")\n",
        "        except AttributeError:\n",
        "            print(\"Could not extract text from the response object.\")\n",
        "            print(\"Full response object:\", response)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while interacting with the Generative AI model: {e}\")\n",
        "\n",
        "# 6. Task completed - Code integrated and commented.\n",
        "print(\"\\nTask completed: Code integrated and commented.\")"
      ],
      "metadata": {
        "id": "g-AecwaHNrI7",
        "outputId": "eca25157-5183-4349-8f25-4268899390d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key loaded successfully.\n",
            "Google Generative AI model 'gemini-1.5-flash' initialized.\n",
            "Please enter your question: Can you classify the following animals as 'Mammal' or 'Bird' based on these examples: 'Dog: Mammal', 'Eagle: Bird', 'Cat: Mammal'?\n",
            "\n",
            "Prompt text created: Can you classify the following animals as 'Mammal' or 'Bird' based on these examples: 'Dog: Mammal', 'Eagle: Bird', 'Cat: Mammal'?\n",
            "Sending prompt to the model...\n",
            "Prompt sent, response received.\n",
            "\n",
            "--- AI Model Response ---\n",
            "Here's a classification based on your examples:\n",
            "\n",
            "* **Dog:** Mammal\n",
            "* **Eagle:** Bird\n",
            "* **Cat:** Mammal\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Task completed: Code integrated and commented.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***2***"
      ],
      "metadata": {
        "id": "l_wSBwZSOE3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 這個腳本允許您直接輸入問題，並可選擇使用進階提示技術與 Google Generative AI 模型互動。\n",
        "\n",
        "# 1. 安裝必要的程式庫\n",
        "# 這行程式碼會安裝 Google Generative AI Python 客戶端程式庫。\n",
        "# 如果您已經安裝過，可以跳過這一步。\n",
        "!pip install google-generativeai -q\n",
        "\n",
        "# 引入必要的程式庫\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# 2. 載入 API 金鑰\n",
        "# 從 Colab 秘密管理員中安全地載入您的 Google AI Studio API 金鑰。\n",
        "# 請務必將您的金鑰新增到秘密管理員中，並將其命名為 'GOOGLE_API_KEY'。\n",
        "api_key = None\n",
        "try:\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    if api_key is None:\n",
        "        print(\"API key not found in Colab Secrets Manager. Please add it as 'GOOGLE_API_KEY'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the API key: {e}\")\n",
        "\n",
        "if not api_key:\n",
        "    print(\"無法載入 API 金鑰，請檢查秘密管理員設定。\")\n",
        "else:\n",
        "    print(\"API 金鑰載入成功。\")\n",
        "    # 3. 初始化 Generative AI 模型\n",
        "    # 使用載入的金鑰初始化 Google Generative AI 模型。\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        # 選擇一個支援 generate_content 方法的模型，例如 'gemini-pro' 或 'gemini-1.5-flash'\n",
        "        # 您可以使用 genai.list_models() 來查看可用的模型\n",
        "        model_name = 'gemini-1.5-flash' # Or 'gemini-pro' or another suitable model\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        print(f\"Google Generative AI 模型 '{model_name}' 已初始化。\")\n",
        "\n",
        "        # --- 使用者輸入提示的程式碼 ---\n",
        "        prompt_text = input(\"請輸入您的問題：\")\n",
        "        # --- 結束使用者輸入提示的程式碼 ---\n",
        "\n",
        "        # --- 新增進階技術選擇及輸入邏輯 ---\n",
        "        use_advanced_technique = input(\"是否要使用進階技術 (Few-shot 或 Chain-of-Thought)? 請輸入 'few-shot', 'cot', 或 '否': \").lower()\n",
        "\n",
        "        few_shot_examples = []\n",
        "        cot_instructions = None\n",
        "        optimized_prompt = prompt_text # 初始化優化後的提示\n",
        "\n",
        "        # 如果使用者選擇使用小樣本技術\n",
        "        if use_advanced_technique == 'few-shot':\n",
        "            print(\"\\n請輸入小樣本範例 (輸入 '完成' 結束):\")\n",
        "            while True:\n",
        "                example_input = input(\"輸入範例: \")\n",
        "                if example_input.lower() == '完成':\n",
        "                    break\n",
        "                example_output = input(\"輸出範例: \")\n",
        "                few_shot_examples.append({'input': example_input, 'output': example_output})\n",
        "\n",
        "            # 建構包含小樣本的提示\n",
        "            for example in few_shot_examples:\n",
        "                optimized_prompt += f\"\\nInput: {example['input']}\\nOutput: {example['output']}\"\n",
        "            optimized_prompt += f\"\\nInput: {prompt_text}\\nOutput:\"\n",
        "\n",
        "        # 如果使用者選擇使用思維鏈技術\n",
        "        elif use_advanced_technique == 'cot':\n",
        "            cot_instructions = input(\"\\n請輸入思維鏈的指示: \")\n",
        "            # 建構包含思維鏈指示的提示\n",
        "            optimized_prompt += f\"\\n{cot_instructions}\"\n",
        "            optimized_prompt += f\"\\nProblem: {prompt_text}\\nLet's think step by step.\"\n",
        "\n",
        "        # 如果使用者選擇不使用進階技術，optimized_prompt 保持為原始 prompt_text\n",
        "        # --- 結束新增進階技術選擇及輸入邏輯 ---\n",
        "\n",
        "\n",
        "        # 4. 傳送提示並捕捉回應\n",
        "        print(f\"\\n傳送給模型的最終提示：\\n---\")\n",
        "        print(optimized_prompt)\n",
        "        print(\"---\")\n",
        "\n",
        "\n",
        "        print(\"\\n正在傳送提示給模型...\")\n",
        "        response = model.generate_content(optimized_prompt) # 使用優化後的提示傳送\n",
        "        print(\"提示已傳送，回應已接收。\")\n",
        "\n",
        "        # 5. 處理並顯示回應\n",
        "        # 獲取模型的生成回應並顯示出來。\n",
        "        try:\n",
        "            response_text = response.text\n",
        "            print(\"\\n--- AI 模型回應 ---\")\n",
        "            print(response_text)\n",
        "            print(\"-------------------------\")\n",
        "        except AttributeError:\n",
        "            print(\"無法從回應物件中提取文字。\")\n",
        "            print(\"完整回應物件：\", response)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"與 Generative AI 模型互動時發生錯誤：{e}\")\n",
        "\n",
        "# 任務完成。您可以再次執行此儲存格來輸入另一個問題。\n",
        "print(\"\\n任務完成。您可以再次執行此儲存格來輸入另一個問題。\")"
      ],
      "metadata": {
        "id": "hjq4y7X7KBhr",
        "outputId": "a03cab41-8fd8-4851-be45-e11f925eac20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API 金鑰載入成功。\n",
            "Google Generative AI 模型 'gemini-1.5-flash' 已初始化。\n",
            "請輸入您的問題：Can you classify the following animals as 'Mammal' or 'Bird' based on these examples: 'Dog: Mammal', 'Eagle: Bird', 'Cat: Mammal'?\n",
            "是否要使用進階技術 (Few-shot 或 Chain-of-Thought)? 請輸入 'few-shot', 'cot', 或 '否': cot\n",
            "\n",
            "請輸入思維鏈的指示: 'Mammal' or 'Bird'\n",
            "\n",
            "傳送給模型的最終提示：\n",
            "---\n",
            "Can you classify the following animals as 'Mammal' or 'Bird' based on these examples: 'Dog: Mammal', 'Eagle: Bird', 'Cat: Mammal'?\n",
            "'Mammal' or 'Bird'\n",
            "Problem: Can you classify the following animals as 'Mammal' or 'Bird' based on these examples: 'Dog: Mammal', 'Eagle: Bird', 'Cat: Mammal'?\n",
            "Let's think step by step.\n",
            "---\n",
            "\n",
            "正在傳送提示給模型...\n",
            "提示已傳送，回應已接收。\n",
            "\n",
            "--- AI 模型回應 ---\n",
            "Based on the examples:\n",
            "\n",
            "* **Dog:** Mammal\n",
            "* **Eagle:** Bird\n",
            "* **Cat:** Mammal\n",
            "\n",
            "We can classify animals as follows:\n",
            "\n",
            "* **Parrot:** Bird\n",
            "* **Cow:** Mammal\n",
            "* **Penguin:** Bird\n",
            "* **Elephant:** Mammal\n",
            "* **Sparrow:** Bird\n",
            "* **Lion:** Mammal\n",
            "\n",
            "-------------------------\n",
            "\n",
            "任務完成。您可以再次執行此儲存格來輸入另一個問題。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation 1 vs. Generation 2: An Optimization Overview\n",
        "The second-generation script significantly improves upon the first by integrating advanced prompting techniques.\n",
        "\n",
        "The first-generation script offered basic interaction: you asked a question, and the model responded. Its effectiveness was limited by the simplicity of a single prompt.\n",
        "\n",
        "In contrast, the second-generation script empowers you to guide the model more precisely. It introduces options for \"Few-shot\" and \"Chain-of-Thought (CoT)\" prompting. Few-shot allows you to provide examples, helping the model learn desired response formats. CoT encourages step-by-step reasoning, improving accuracy for complex problems.\n",
        "\n",
        "Ultimately, the second-generation script transforms a basic tool into a more sophisticated platform, enabling smarter prompt engineering for higher-quality AI outputs."
      ],
      "metadata": {
        "id": "WhFyug7tNjU1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "歡迎使用 Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}